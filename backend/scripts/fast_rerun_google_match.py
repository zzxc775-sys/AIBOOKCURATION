from full_incremental_pipeline import fetch_google_book_info
import pandas as pd
from concurrent.futures import ThreadPoolExecutor, as_completed

# 1. 2600í˜ì´ì§€ê¹Œì§€ ìˆ˜ì§‘í•œ ISBN ë°ì´í„° ë¡œë“œ
all_books = pd.read_csv("data/books_partial_2600.csv")

# 2. Google Books APIë¡œ description ë¹ ë¥´ê²Œ ìˆ˜ì§‘
def fetch_info(isbn):
    return fetch_google_book_info(isbn)

matched_books = []
target_isbns = all_books["isbn"].dropna().unique()  # ì¤‘ë³µ, NaN ì œê±°

print(f"â–¶ Google Books ì„¤ëª… ìˆ˜ì§‘ (ë©€í‹°ìŠ¤ë ˆë“œ): ì´ {len(target_isbns)}ê¶Œ")

# 3. ë³‘ë ¬ ìš”ì²­ (15ê°œ ìŠ¤ë ˆë“œ)
with ThreadPoolExecutor(max_workers=15) as executor:
    futures = {executor.submit(fetch_info, isbn): isbn for isbn in target_isbns}
    for i, future in enumerate(as_completed(futures), start=1):
        result = future.result()
        if result and result["description"]:
            matched_books.append(result)
            print(f"âœ… [{i}/{len(target_isbns)}] {result['title']}")
        else:
            print(f"âš ï¸ [{i}/{len(target_isbns)}] ì„¤ëª… ì—†ìŒ")

# 4. ê²°ê³¼ CSV ì €ì¥ (ë‚˜ì¤‘ì— sort.pyë¡œ í•©ì¹˜ê¸° ê°€ëŠ¥)
pd.DataFrame(matched_books).to_csv(
    "data/books_with_descriptions_resume.csv",
    index=False,
    encoding="utf-8-sig"
)
print(f"ğŸ“ {len(matched_books)}ê¶Œ description ìˆ˜ì§‘ ì™„ë£Œ (books_partial_2600 ê¸°ì¤€)")
